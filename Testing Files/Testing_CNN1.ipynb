{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jb_Sgluvq7ou"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Torch\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import pathlib\n",
        "from torchvision import models\n",
        "from sklearn.metrics import precision_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se5Jb1Udq7ov",
        "outputId": "b8585512-f0e5-4d0c-b249-11bcfa01a8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L073MaJjrMSI",
        "outputId": "a93a6d1b-feeb-4c5a-e613-241339737f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([\n",
        "    # Resize the image to (160, 160)\n",
        "    transforms.Resize((160, 160)),\n",
        "    # Convert the image to grayscale only one channel\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "\n",
        "    #Data Augmentation\n",
        "    transforms.RandomHorizontalFlip(),       # Randomly flip the image horizontally\n",
        "    transforms.RandomRotation(degrees=15),   # Randomly rotate the image by up to 15 degrees\n",
        "    transforms.ToTensor(),                   # Convert the image to a PyTorch tensor\n",
        "])\n"
      ],
      "metadata": {
        "id": "hUo9xwvOSyTm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/DL Submission/test'\n",
        "test_loader = DataLoader(torchvision.datasets.ImageFolder(\n",
        "                          test_path,\n",
        "                          transform=transformer),\n",
        "                          batch_size = 128,\n",
        "                          shuffle=False)"
      ],
      "metadata": {
        "id": "zpBkU2zwHrA0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hK0WKVVYq7o0"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self,num_classes=2):\n",
        "    super(ConvNet,self).__init__()\n",
        "    # input shape (256,1, 160,160)\n",
        "\n",
        "    #output shape ((width-kernel+2P)/stride)+1 160-3+2+1=160\n",
        "    self.conv1 =nn.Conv2d(in_channels=1,out_channels=20,kernel_size=3,stride=1,padding=1) # outptu channels is the number of kernels used\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=20)\n",
        "    self.sigmoid1 = nn.Sigmoid()\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=20,out_channels = 32,kernel_size =3,stride=1,padding=1)\n",
        "    #256*20*80*80\n",
        "    self.bn2=nn.BatchNorm2d(num_features=32)\n",
        "    self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "    #shape = 256*12*80*80 (reduce image size by 2)\n",
        "    self.sigmoid2 = nn.Sigmoid()\n",
        "\n",
        "    #256*20*80*80\n",
        "    self.conv3 = nn.Conv2d(in_channels=32,out_channels =64,kernel_size =3,stride =1 ,padding=1)\n",
        "#     #256*32*80*80\n",
        "    self.bn3 = nn.BatchNorm2d(num_features=64)\n",
        "    self.sigmoid3 =nn.Sigmoid()\n",
        "\n",
        "    self.fc = nn.Linear(in_features=64*80*80,out_features = 2)\n",
        "\n",
        "  def forward(self,input):\n",
        "    output = self.conv1(input)\n",
        "    output = self.bn1(output)\n",
        "    output = self.sigmoid1(output)\n",
        "    output = self.conv2(output)\n",
        "    output = self.bn2(output)\n",
        "    output = self.pool(output)\n",
        "    output = self.sigmoid2(output)\n",
        "    output = self.conv3(output)\n",
        "    output = self.bn3(output)\n",
        "    output = self.sigmoid3(output)\n",
        "\n",
        "    output = output.view(-1,64*80*80)\n",
        "    output = self.fc(output)\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5fkMXSFdq7o1"
      },
      "outputs": [],
      "source": [
        "model = ConvNet(num_classes=2).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpt2_oXkq7o1"
      },
      "source": [
        "Testing on test data(unseen data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SwZG_617q7o1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da9f4b3-72c1-40fa-aaf6-7a856a3c26db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 85.42%\n",
            "Precision: 86.22%\n",
            "F1 Score: 83.69%\n"
          ]
        }
      ],
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/DL Submission/Best_model_CNN1_Sig_adagrad_128_0.001.pt'\n",
        "state_dict = torch.load(model_path,map_location=device)\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "model.to(device)\n",
        "\n",
        "#to calulate eval later\n",
        "predicted_list = []\n",
        "target_list =[]\n",
        "#set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "total_images_test = len(test_loader.dataset)\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_correct += (predicted == targets).sum().item()\n",
        "        predicted_list.extend(predicted.cpu().numpy())\n",
        "        target_list.extend(targets.cpu().numpy())\n",
        "\n",
        "accuracy = total_correct / total_images_test\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "precision = precision_score(target_list, predicted_list, average='macro')\n",
        "print(f'Precision: {precision * 100:.2f}%')\n",
        "\n",
        "f1 = f1_score(target_list, predicted_list, average='macro')\n",
        "print(f'F1 Score: {f1 * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Single Images"
      ],
      "metadata": {
        "id": "JtSnJfP6BqZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Load the image\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/good_lungs.png'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Apply transformations\n",
        "input_image = transformer(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "# Load the model\n",
        "model = ConvNet(num_classes=2)\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/DL Submission/Best_model_CNN1_Sig_adagrad_128_0.001.pt'\n",
        "state_dict = torch.load(model_path,map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "# Make prediction\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "# Print prediction\n",
        "if predicted_class==0:\n",
        "  print('NORMAL')\n",
        "if predicted_class==1:\n",
        "  print('PNEMONIA')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgPOM4l-pakL",
        "outputId": "aff056a3-fc38-49d3-87b8-9a031624d8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NORMAL\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 17810,
          "sourceId": 23812,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}