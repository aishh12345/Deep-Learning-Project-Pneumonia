{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":9666,"status":"ok","timestamp":1712409502820,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"},"user_tz":-480},"id":"jb_Sgluvq7ou"},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","# Torch\n","import torch\n","import torchvision\n","from torchvision import datasets,transforms\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","from torch.autograd import Variable\n","import pathlib"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1712409502822,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"},"user_tz":-480},"id":"Se5Jb1Udq7ov","outputId":"536ffb76-00a1-43b1-bad5-9c66bfff50dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"HIiVefUHq7ow"},"source":["Apply transformations to augment data"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3303,"status":"ok","timestamp":1712415942377,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"},"user_tz":-480},"id":"L073MaJjrMSI","outputId":"9d5da330-11e5-4788-c29c-befe3a149ef7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["transformer = transforms.Compose([\n","    # Resize the image to (160, 160)\n","    transforms.Resize((160, 160)),\n","    # Convert the image to grayscale only one channel\n","    transforms.Grayscale(num_output_channels=1),\n","\n","    #Data Augmentation\n","    #Randomly flip the image horizontally\n","    transforms.RandomHorizontalFlip(),       # Randomly flip the image horizontally\n","    transforms.RandomRotation(degrees=15),   # Randomly rotate the image by up to 15 degrees\n","    transforms.ToTensor(),                   # Convert the image to a PyTorch tensor\n","])\n"],"metadata":{"id":"hUo9xwvOSyTm","executionInfo":{"status":"ok","timestamp":1712409529952,"user_tz":-480,"elapsed":5,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YRH5m_joq7oy","executionInfo":{"status":"ok","timestamp":1712409577901,"user_tz":-480,"elapsed":42723,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"}}},"outputs":[],"source":["#DataLoader\n","\n","batchSize=128\n","train_path = '/content/drive/MyDrive/Colab Notebooks/chest_xray/train'\n","train_loader = DataLoader(torchvision.datasets.ImageFolder(\n","                          train_path,\n","                          transform=transformer),\n","                          batch_size = batchSize,\n","                          shuffle=True)\n","val_path = '/content/drive/MyDrive/Colab Notebooks/chest_xray/val'\n","val_loader = DataLoader(torchvision.datasets.ImageFolder(\n","                          val_path,\n","                          transform=transformer),\n","                          batch_size = batchSize)\n","\n","test_path = '/content/drive/MyDrive/Colab Notebooks/chest_xray/test'\n","test_loader = DataLoader(torchvision.datasets.ImageFolder(\n","                          test_path,\n","                          transform=transformer),\n","                          batch_size = batchSize,\n","                          shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1712405076493,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"},"user_tz":-480},"id":"XlAxtvnZq7oz","outputId":"97abd386-b768-4fc2-cc0a-90aa9148438e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['NORMAL', 'PNEUMONIA']\n"]}],"source":["root=pathlib.Path(train_path)\n","classes = sorted([j.name.split('/')[-1]for j in root.iterdir()])\n","print(classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7299,"status":"ok","timestamp":1712377962816,"user":{"displayName":"gpuaccount1","userId":"01712468119059258597"},"user_tz":-480},"id":"pAn181Spq7o0","outputId":"c32dfd5d-3dbf-4a4a-df59-1d237ba020de"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 160, 160])\n"]}],"source":["sample_image, sample_label = train_loader.dataset[0]\n","print(sample_image.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"hK0WKVVYq7o0","executionInfo":{"status":"ok","timestamp":1712409590023,"user_tz":-480,"elapsed":501,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"}}},"outputs":[],"source":["class ConvNet(nn.Module):\n","  def __init__(self,num_classes=2):\n","    super(ConvNet,self).__init__()\n","    # input shape (256,1, 160,160)\n","\n","    #output shape ((width-kernel+2P)/stride)+1 160-3+2+1=160\n","    self.conv1 =nn.Conv2d(in_channels=1,out_channels=20,kernel_size=3,stride=1,padding=1) # outptu channels is the number of kernels used\n","\n","    self.bn1 = nn.BatchNorm2d(num_features=20)\n","    self.sigmoid1 = nn.Sigmoid()\n","#     self.relu1 = nn.ReLU()\n","\n","\n","    self.conv2 = nn.Conv2d(in_channels=20,out_channels = 32,kernel_size =3,stride=1,padding=1)\n","    #256*20*80*80\n","    self.bn2=nn.BatchNorm2d(num_features=32)\n","    self.pool=nn.MaxPool2d(kernel_size=2)\n","    #shape = 256*12*80*80 (reduce image size by 2)\n","    self.sigmoid2 = nn.Sigmoid()\n","#     self.relu2 = nn.ReLU()\n","    #256*20*80*80\n","    self.conv3 = nn.Conv2d(in_channels=32,out_channels =64,kernel_size =3,stride =1 ,padding=1)\n","#     #256*32*80*80\n","    self.bn3 = nn.BatchNorm2d(num_features=64)\n","    self.sigmoid3 =nn.Sigmoid()\n","#     self.relu3 = nn.ReLU()\n","\n","    self.fc = nn.Linear(in_features=64*80*80,out_features = 2)\n","\n","  def forward(self,input):\n","    output = self.conv1(input)\n","    output = self.bn1(output)\n","    output = self.sigmoid1(output)\n","#     output = self.relu1(output)\n","    output = self.conv2(output)\n","    output = self.bn2(output)\n","    output = self.pool(output)\n","    output = self.sigmoid2(output)\n","#     output = self.relu2(output)\n","    output = self.conv3(output)\n","    output = self.bn3(output)\n","    output = self.sigmoid3(output)\n","#     output = self.relu3(output)\n","\n","    output = output.view(-1,64*80*80)\n","    output = self.fc(output)\n","    return output\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5fkMXSFdq7o1","executionInfo":{"status":"ok","timestamp":1712409612696,"user_tz":-480,"elapsed":4,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"}}},"outputs":[],"source":["import torch.optim as optim\n","model = ConvNet(num_classes=2).to(device)"]},{"cell_type":"markdown","metadata":{"id":"Qpt2_oXkq7o1"},"source":["Testing on test data"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"SwZG_617q7o1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712417938698,"user_tz":-480,"elapsed":11669,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"}},"outputId":"82153532-b6ac-403c-9a81-f9f0765b6038"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 76.44%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models  # Assuming you have torchvision installed\n","\n","# Load the saved model's state dictionary\n","model_path = '/content/drive/MyDrive/Colab Notebooks/Sig_adam_128_0.001.pt'\n","state_dict = torch.load(model_path)\n","\n","# Load the state dictionary into the model\n","model.load_state_dict(state_dict)\n","model.to(device)\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","# Iterate through the test loader and get predictions\n","total_correct = 0\n","total_samples = 0\n","with torch.no_grad():\n","    for inputs, targets in test_loader:\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        # Compute accuracy\n","        total_samples += targets.size(0)\n","        total_correct += (predicted == targets).sum().item()\n","\n","# Calculate the overall accuracy\n","accuracy = total_correct / total_samples\n","print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"]},{"cell_type":"markdown","source":["Testing Single Images"],"metadata":{"id":"JtSnJfP6BqZu"}},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","from torchvision import transforms\n","\n","transformer = transforms.Compose([\n","    # Resize the image to (160, 160)\n","    transforms.Resize((160, 160)),\n","    # Convert the image to grayscale only one channel\n","    transforms.Grayscale(num_output_channels=1),\n","\n","    #Data Augmentation\n","    #Randomly flip the image horizontally\n","    transforms.RandomHorizontalFlip(),       # Randomly flip the image horizontally\n","    transforms.RandomRotation(degrees=15),   # Randomly rotate the image by up to 15 degrees\n","    transforms.ToTensor(),                   # Convert the image to a PyTorch tensor\n","])\n","\n","\n","# Load the image\n","image_path = '/content/drive/MyDrive/Colab Notebooks/normal.png'\n","image = Image.open(image_path)\n","\n","# Apply transformations\n","input_image = transformer(image).unsqueeze(0)  # Add a batch dimension\n","\n","# Load the model\n","model = ConvNet(num_classes=2)\n","model_path = '/content/drive/MyDrive/Colab Notebooks/Sig_adagrad_128_0.001.pt'\n","state_dict = torch.load(model_path)\n","model.load_state_dict(state_dict)\n","model.eval()\n","\n","# Make prediction\n","with torch.no_grad():\n","    output = model(input_image)\n","    _, predicted_class = torch.max(output, 1)\n","\n","# Print prediction\n","if predicted_class==0:\n","  print('NORMAL')\n","if predicted_class==1:\n","  print('PNEMONIA')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RgPOM4l-pakL","executionInfo":{"status":"ok","timestamp":1712417380455,"user_tz":-480,"elapsed":889,"user":{"displayName":"Palaniappan Aishwarya","userId":"13953511142047769779"}},"outputId":"7f16d9f3-9cb1-4575-cfe1-d543890fc01d"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["NORMAL\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":17810,"sourceId":23812,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}