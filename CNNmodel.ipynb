{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4m5sKoSL6uNR","executionInfo":{"status":"ok","timestamp":1710732128412,"user_tz":-480,"elapsed":7447,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","# Torch\n","import torch\n","import torchvision\n","from torchvision import datasets,transforms\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","from torch.autograd import Variable\n","import pathlib"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YdMQw_tjcz-L","executionInfo":{"status":"ok","timestamp":1710732128413,"user_tz":-480,"elapsed":8,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[],"source":["device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710732128413,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"},"user_tz":-480},"id":"JMH5euJOd28t","outputId":"b7310f10-27a8-433d-d6f2-12b61c633430"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["print(device)"]},{"cell_type":"markdown","metadata":{"id":"NAZixnqWtRyY"},"source":["Load Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"AzGvONLOso5M","executionInfo":{"status":"ok","timestamp":1710732238116,"user_tz":-480,"elapsed":381,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[],"source":["transformer = transforms.Compose([transforms.Resize((150,150)),\n","                                  transforms.Grayscale(num_output_channels=1),\n","                                  transforms.RandomHorizontalFlip(),\n","                                 transforms.ToTensor(), # chnages from 0-255 to 0-1, numpy to tensors\n","                                  transforms.Normalize([0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n","                        [0.5])\n","                                 ])"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"m11PPRej_NBc","executionInfo":{"status":"ok","timestamp":1710732304177,"user_tz":-480,"elapsed":2752,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[],"source":["#DataLoader\n","\n","batchSize=64\n","train_path = '/content/drive/MyDrive/Deep Learning Project/chest_xray/train'\n","train_loader = DataLoader(torchvision.datasets.ImageFolder(\n","                          train_path,\n","                          transform=transformer),\n","                          batch_size = batchSize,\n","                          shuffle=True)\n","val_path = '/content/drive/MyDrive/Deep Learning Project/chest_xray/val'\n","val_loader = DataLoader(torchvision.datasets.ImageFolder(\n","                          val_path,\n","                          transform=transformer),\n","                          batch_size = batchSize)\n","\n","test_path = '/content/drive/MyDrive/Deep Learning Project/chest_xray/test'\n","test_loader = DataLoader(torchvision.datasets.ImageFolder(\n","                          test_path,\n","                          transform=transformer),\n","                          batch_size = batchSize,\n","                          shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"19j3Un3skDwb"},"outputs":[],"source":["# from torch.utils.data import Subset, ConcatDataset\n","# from torch.utils.data import Dataset\n","# # Specify the number of samples you want to include from class 2\n","# num_samples_class2 = 1500\n","\n","# # Get indices of samples belonging to class 1 and class 2\n","# class2_indices = [idx for idx, (img, label) in enumerate(train_loader.dataset) if label == 'PNEUMONIA']\n","\n","# # Create a Subset dataset containing all samples from class 1\n","# class1_dataset = train_loader.dataset\n","\n","# # Take a subset of samples from class 2 based on the specified number\n","# class2_subset_indices = class2_indices[:num_samples_class2]\n","\n","# # Create a Subset dataset containing samples from class 2\n","# class2_subset_dataset = Subset(train_loader.dataset, class2_subset_indices)\n","\n","# # Concatenate the Subset datasets to create a single dataset containing samples from both classes\n","# combined_dataset = ConcatDataset([class1_dataset, class2_subset_dataset])\n","\n","# # Create DataLoader for the combined dataset\n","# combined_train_loader = DataLoader(combined_dataset, batch_size=64, shuffle=True)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91435,"status":"ok","timestamp":1710732222071,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"},"user_tz":-480},"id":"XVZh19aB5vXl","outputId":"6af87090-1af9-40e6-eef9-6ec24c5664d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r23cF8vHoMMc"},"outputs":[],"source":["# from torch.utils.data import Subset\n","\n","# # Define the number of images you want to load\n","# train_subset_indices = range(3000)\n","# test_subset_indices = range(500)\n","\n","# # Create subsets of the dataset\n","# train_subset = Subset(train_loader.dataset, train_subset_indices)\n","# test_subset = Subset(test_loader.dataset, test_subset_indices)\n","\n","# # Create loaders for the subsets\n","# train_loader_subset = DataLoader(train_subset, batch_size=batchSize, shuffle=True)\n","# test_loader_subset = DataLoader(test_subset, batch_size=batchSize, shuffle=False)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710734880901,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"},"user_tz":-480},"id":"8ZHh_J5UsBYR","outputId":"22b9fdeb-637d-4d3a-d312-4a1b893184ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of images in the training dataset: 2880\n","Total number of images in the test dataset: 397\n","Total number of images in the validation dataset: 227\n","2880\n"]}],"source":["\n","total_images_train = len(train_loader.dataset)\n","\n","print(\"Total number of images in the training dataset:\", total_images_train)\n","\n","total_images_test = len(test_loader.dataset)\n","\n","print(\"Total number of images in the test dataset:\", total_images_test)\n","\n","total_images_train = len(val_loader.dataset)\n","\n","print(\"Total number of images in the validation dataset:\", total_images_train)\n","\n","print(total_images_train)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1345,"status":"ok","timestamp":1710732372208,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"},"user_tz":-480},"id":"yL2MQ5S7mpD1","outputId":"7df8d187-abda-4dbd-c2dd-79e79bc2fdf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 150, 150])\n"]}],"source":["sample_image, sample_label = train_loader.dataset[0]\n","print(sample_image.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1710732373578,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"},"user_tz":-480},"id":"hVRpOvtufAJX","outputId":"6420e861-f1dc-4ef3-ba4b-9a6559a0da62"},"outputs":[{"output_type":"stream","name":"stdout","text":["['NORMAL', 'PNEUMONIA']\n"]}],"source":["root=pathlib.Path(train_path)\n","classes = sorted([j.name.split('/')[-1]for j in root.iterdir()])\n","print(classes)"]},{"cell_type":"markdown","metadata":{"id":"d7EHB0hPhjQR"},"source":["Convolutional Neural Network Architetuire"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"aM2FbbMshi2i","executionInfo":{"status":"ok","timestamp":1710732375879,"user_tz":-480,"elapsed":2,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[],"source":["class ConvNet(nn.Module):\n","  def __init__(self,num_classes=2):\n","    super(ConvNet,self).__init__()\n","    # input shape (256,1, 150,150)\n","\n","    #output shape ((width-kernel+2P)/stride)+1 150-3+2+1=150\n","    self.conv1 =nn.Conv2d(in_channels=1,out_channels=20,kernel_size=5,stride=1,padding=2) # outptu channels is the number of kernels used\n","    #shape = 256*12*150*150\n","    self.bn1 = nn.BatchNorm2d(num_features=20)\n","    self.relu1 = nn.ReLU()\n","    self.pool=nn.MaxPool2d(kernel_size=2)\n","    #shape = 256*12*75*75 (reduce image size by 2)\n","\n","    self.conv2 = nn.Conv2d(in_channels=20,out_channels = 32,kernel_size =5,stride=1,padding=2)\n","    #256*20*75*75\n","    self.bn2=nn.BatchNorm2d(num_features=32)\n","    self.dropout1 = nn.Dropout(0.5) # 50 % of neurons will be zero\n","    self.relu2 = nn.ReLU()\n","    #256*20*75*75\n","    self.conv3 = nn.Conv2d(in_channels=32,out_channels =64,kernel_size =3,stride =1 ,padding=1)\n","#     #256*32*75*75\n","    self.bn3 = nn.BatchNorm2d(num_features=64)\n","    self.relu3 =nn.ReLU()\n","\n","\n","    self.fc = nn.Linear(in_features=64*75*75,out_features = 2)\n","\n","  def forward(self,input):\n","    output = self.conv1(input)\n","    output = self.bn1(output)\n","    output = self.relu1(output)\n","    output = self.pool(output)\n","    output = self.conv2(output)\n","    output = self.bn2(output)\n","    output= self.dropout1(output)\n","    output = self.relu2(output)\n","    output = self.conv3(output)\n","    output = self.bn3(output)\n","    output = self.relu3(output)\n","\n","    output = output.view(-1,64*75*75)\n","    output = self.fc(output)\n","    return output\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"SLDsHTTjn1EE","executionInfo":{"status":"ok","timestamp":1710732379022,"user_tz":-480,"elapsed":3,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[],"source":["model = ConvNet(num_classes=2).to(device)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"xUTdvVBdonhg","executionInfo":{"status":"ok","timestamp":1710734311442,"user_tz":-480,"elapsed":407,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[],"source":["optimizer =Adam(model.parameters(),lr = 0.001,weight_decay=0.0001)\n","loss_function = nn.CrossEntropyLoss()\n","# loss_function = nn.BCELoss()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"qRqv7bFZo7nn","executionInfo":{"status":"ok","timestamp":1710732390388,"user_tz":-480,"elapsed":2,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[],"source":["num_epochs =5"]},{"cell_type":"markdown","metadata":{"id":"E6RJcoBrpHM5"},"source":["Model Training"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":686},"id":"RdzOT_NoyvI5","outputId":"f6e65291-2f20-43e4-8c9a-701a83aad0cc","executionInfo":{"status":"error","timestamp":1710735410943,"user_tz":-480,"elapsed":478915,"user":{"displayName":"gpuuse2","userId":"10933453146467445082"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2819.0\n","227\n","Epoch: 0 Train Loss: tensor(0.6051) Train Accuracy: 0.9788194444444445 Test Accuracy: 0.8035264483627204\n","2842.0\n","227\n","Epoch: 1 Train Loss: tensor(0.3517) Train Accuracy: 0.9868055555555556 Test Accuracy: 0.7783375314861462\n","2794.0\n","227\n","Epoch: 2 Train Loss: tensor(0.7973) Train Accuracy: 0.9701388888888889 Test Accuracy: 0.7707808564231738\n","2830.0\n","227\n","Epoch: 3 Train Loss: tensor(0.4554) Train Accuracy: 0.9826388888888888 Test Accuracy: 0.7657430730478589\n","2845.0\n","227\n","Epoch: 4 Train Loss: tensor(0.1776) Train Accuracy: 0.9878472222222222 Test Accuracy: 0.7984886649874056\n","2855.0\n","227\n","Epoch: 5 Train Loss: tensor(0.1519) Train Accuracy: 0.9913194444444444 Test Accuracy: 0.7858942065491183\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-d4fba8e2a1d8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","from torch.autograd import Variable\n","best_accuracy=0.0\n","#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n","iterations=[]\n","for epoch in range(num_epochs):\n","\n","    #Evaluation and training on training dataset\n","    model.train()\n","    train_accuracy=0.0\n","    train_loss=0.0\n","\n","\n","    for i, (images,labels) in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","            images=Variable(images.cuda())\n","            labels=Variable(labels.cuda())\n","\n","        optimizer.zero_grad()\n","\n","        outputs=model(images)\n","        #using cross entropy loss (can explore BCE also)\n","        loss=loss_function(outputs,labels)\n","        #to calculate the loss wrt teh parameters and start backpropagation\n","        loss.backward()\n","        #to update the weights\n","        optimizer.step()\n","\n","\n","        train_loss+= loss.cpu().data*images.size(0)\n","        _,prediction=torch.max(outputs.data,1)\n","\n","        # train_accuracy+=int(torch.sum(prediction==labels.data))\n","        train_accuracy += torch.sum(prediction == labels.data).item()\n","\n","    print(train_accuracy)\n","    train_accuracy=train_accuracy/len(train_loader.dataset)\n","    train_loss=train_loss/len(train_loader.dataset)\n","    # Evaluation on testing dataset\n","    model.eval()\n","\n","    test_accuracy=0.0\n","    for i, (images,labels) in enumerate(test_loader):\n","        if torch.cuda.is_available():\n","            images=Variable(images.cuda())\n","            labels=Variable(labels.cuda())\n","\n","        outputs=model(images)\n","        _,prediction=torch.max(outputs.data,1)\n","        test_accuracy+=int(torch.sum(prediction==labels.data))\n","\n","    test_accuracy=test_accuracy/total_images_test\n","\n","\n","    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n","    # scheduler.step(test_accuracy)\n","\n","    #Save the best model\n","    # if test_accuracy>best_accuracy:\n","    #     torch.save(model.state_dict(),'best_checkpoint.model')\n","    #     best_accuracy=test_accuracy\n"]},{"cell_type":"code","source":["from torch.autograd import Variable\n","import matplotlib.pyplot as plt\n","\n","best_accuracy = 0.0\n","train_accuracies = []\n","test_accuracies = []\n","\n","#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n","\n","for epoch in range(num_epochs):\n","\n","    #Evaluation and training on training dataset\n","    model.train()\n","    train_accuracy = 0.0\n","    train_loss = 0.0\n","\n","    for i, (images, labels) in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        #using cross entropy loss (can explore BCE also)\n","        loss = loss_function(outputs, labels)\n","        #to calculate the loss wrt the parameters and start backpropagation\n","        loss.backward()\n","        #to update the weights\n","        optimizer.step()\n","\n","        train_loss += loss.cpu().data * images.size(0)\n","        _, prediction = torch.max(outputs.data, 1)\n","\n","        train_accuracy += torch.sum(prediction == labels.data).item()\n","\n","    train_accuracy = train_accuracy / len(train_loader.dataset)\n","    train_loss = train_loss / len(train_loader.dataset)\n","\n","    train_accuracies.append(train_accuracy)\n","\n","    # Evaluation on testing dataset\n","    model.eval()\n","    test_accuracy = 0.0\n","\n","    for i, (images, labels) in enumerate(test_loader):\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","\n","        outputs = model(images)\n","        _, prediction = torch.max(outputs.data, 1)\n","        test_accuracy += int(torch.sum(prediction == labels.data))\n","\n","    test_accuracy = test_accuracy / total_images_test\n","    test_accuracies.append(test_accuracy)\n","\n","    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) + ' Train Accuracy: ' + str(train_accuracy) + ' Test Accuracy: ' + str(test_accuracy))\n","    # scheduler.step(test_accuracy)\n","\n","# Plotting\n","iterations = range(1, num_epochs + 1)\n","plt.plot(iterations, train_accuracies, label='Training Accuracy')\n","plt.plot(iterations, test_accuracies, label='Test Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Test Accuracy Over Epochs')\n","plt.legend()\n","plt.show()\n","\n","# Save the best model\n","# if test_accuracy > best_accuracy:\n","#     torch.save(model.state_dict(), 'best_checkpoint.model')\n","#     best_accuracy = test_accuracy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_WdnH1rxsuu","outputId":"3e5c5510-ddf3-46a5-85b7-5d3e13dde176"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 Train Loss: tensor(0.1871) Train Accuracy: 0.9888888888888889 Test Accuracy: 0.8337531486146096\n","Epoch: 1 Train Loss: tensor(0.1064) Train Accuracy: 0.99375 Test Accuracy: 0.7884130982367759\n","Epoch: 2 Train Loss: tensor(0.1146) Train Accuracy: 0.9934027777777777 Test Accuracy: 0.7556675062972292\n","Epoch: 3 Train Loss: tensor(0.2395) Train Accuracy: 0.9888888888888889 Test Accuracy: 0.8085642317380353\n","Epoch: 4 Train Loss: tensor(0.1978) Train Accuracy: 0.9902777777777778 Test Accuracy: 0.8136020151133502\n","Epoch: 5 Train Loss: tensor(0.3380) Train Accuracy: 0.9850694444444444 Test Accuracy: 0.801007556675063\n","Epoch: 6 Train Loss: tensor(0.1373) Train Accuracy: 0.9916666666666667 Test Accuracy: 0.7959697732997482\n","Epoch: 7 Train Loss: tensor(0.0818) Train Accuracy: 0.9961805555555555 Test Accuracy: 0.7959697732997482\n"]}]},{"cell_type":"code","source":["\n","from torch.autograd import Variable\n","best_accuracy=0.0\n","#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n","\n","for epoch in range(num_epochs):\n","\n","    #Evaluation and training on training dataset\n","    model.train()\n","    train_accuracy=0.0\n","    train_loss=0.0\n","\n","    for i, (images,labels) in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","            images=Variable(images.cuda())\n","            labels=Variable(labels.cuda())\n","\n","        optimizer.zero_grad()\n","\n","        outputs=model(images)\n","        #using cross entropy loss (can explore BCE also)\n","        loss=loss_function(outputs,labels)\n","        #to calculate the loss wrt teh parameters and start backpropagation\n","        loss.backward()\n","        #to update the weights\n","        optimizer.step()\n","\n","\n","        train_loss+= loss.cpu().data*images.size(0)\n","        _,prediction=torch.max(outputs.data,1)\n","\n","        train_accuracy+=int(torch.sum(prediction==labels.data))\n","\n","\n","    print(train_accuracy)\n","    print(total_images_train)\n","    train_accuracy=train_accuracy/total_images_train\n","    train_loss=train_loss/total_images_train\n","    # Evaluation on testing dataset\n","    model.eval()\n","\n","    test_accuracy=0.0\n","    for i, (images,labels) in enumerate(test_loader):\n","        if torch.cuda.is_available():\n","            images=Variable(images.cuda())\n","            labels=Variable(labels.cuda())\n","\n","        outputs=model(images)\n","        _,prediction=torch.max(outputs.data,1)\n","        test_accuracy+=int(torch.sum(prediction==labels.data))\n","\n","    test_accuracy=test_accuracy/total_images_test\n","\n","\n","    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n","    # scheduler.step(test_accuracy)\n","\n","    #Save the best model\n","    # if test_accuracy>best_accuracy:\n","    #     torch.save(model.state_dict(),'best_checkpoint.model')\n","    #     best_accuracy=test_accuracy\n"],"metadata":{"id":"m9uxyf-1vROE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIvzA983bu33"},"source":["Accuracy: 0.79"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"agQRz_sGZfjm"},"outputs":[],"source":["class ConvNet(nn.Module):\n","  def __init__(self,num_classes=2):\n","    super(ConvNet,self).__init__()\n","    # input shape (256,1, 150,150)\n","\n","    #output shape ((width-kernel+2P)/stride)+1 150-3+2+1=150\n","    self.conv1 =nn.Conv2d(in_channels=1,out_channels=12,kernel_size=3,stride=1,padding=1) # outptu channels is the number of kernels used\n","    #shape = 256*12*150*150\n","    self.bn1 = nn.BatchNorm2d(num_features=12)\n","    self.relu1 = nn.ReLU()\n","    self.pool=nn.MaxPool2d(kernel_size=2)\n","    #shape = 256*12*75*75 (reduce image size by 2)\n","\n","    self.conv2 = nn.Conv2d(in_channels=12,out_channels = 20,kernel_size =3,stride=1,padding=1)\n","    #256*20*75*75\n","    self.relu2 = nn.ReLU()\n","    #256*20*75*75\n","\n","    self.conv3 = nn.Conv2d(in_channels=20,out_channels =32,kernel_size =3,stride =1 ,padding=1)\n","    #256*32*75*75\n","    self.bn2 = nn.BatchNorm2d(num_features=32)\n","    self.relu3 =nn.ReLU()\n","\n","    self.fc = nn.Linear(in_features=32*75*75,out_features = 2)\n","\n","  def forward(self,input):\n","    output = self.conv1(input)\n","    output = self.bn1(output)\n","    output = self.relu1(output)\n","    output = self.pool(output)\n","    output = self.conv2(output)\n","    output = self.relu2(output)\n","    output = self.conv3(output)\n","    output = self.bn2(output)\n","    output = self.relu3(output)\n","    output = output.view(-1,32*75*75)\n","    output = self.fc(output)\n","    return output\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VvNYkHDfbxmb"},"source":["Accuracy: 0.78"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kk4pzumJbzmj"},"outputs":[],"source":["class ConvNet(nn.Module):\n","  def __init__(self,num_classes=2):\n","    super(ConvNet,self).__init__()\n","    # input shape (256,1, 150,150)\n","\n","    #output shape ((width-kernel+2P)/stride)+1 150-3+2+1=150\n","    self.conv1 =nn.Conv2d(in_channels=1,out_channels=12,kernel_size=3,stride=1,padding=1) # outptu channels is the number of kernels used\n","    #shape = 256*12*150*150\n","    self.bn1 = nn.BatchNorm2d(num_features=12)\n","    self.relu1 = nn.ReLU()\n","    self.pool=nn.MaxPool2d(kernel_size=2)\n","    #shape = 256*12*75*75 (reduce image size by 2)\n","\n","    self.conv2 = nn.Conv2d(in_channels=12,out_channels = 20,kernel_size =3,stride=1,padding=1)\n","    #256*20*75*75\n","    self.bn2=nn.BatchNorm2d(num_features=20)\n","    self.relu2 = nn.ReLU()\n","    #256*20*75*75\n","    self.conv3 = nn.Conv2d(in_channels=20,out_channels =64,kernel_size =3,stride =1 ,padding=1)\n","#     #256*32*75*75\n","    self.bn3 = nn.BatchNorm2d(num_features=64)\n","    self.relu3 =nn.ReLU()\n","\n","\n","    self.fc = nn.Linear(in_features=64*75*75,out_features = 2)\n","\n","  def forward(self,input):\n","    output = self.conv1(input)\n","    output = self.bn1(output)\n","    output = self.relu1(output)\n","    output = self.pool(output)\n","    output = self.conv2(output)\n","    output = self.bn2(output)\n","    output = self.relu2(output)\n","    output = self.conv3(output)\n","    output = self.bn3(output)\n","    output = self.relu3(output)\n","\n","    output = output.view(-1,64*75*75)\n","    output = self.fc(output)\n","    return output\n","\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}